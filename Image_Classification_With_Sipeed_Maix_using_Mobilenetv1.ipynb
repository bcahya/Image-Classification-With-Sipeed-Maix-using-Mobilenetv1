{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Classification With Sipeed Maix using Mobilenetv1",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prOt_VofnYCo"
      },
      "source": [
        "#Image Classification using Sipeed AIoT.\n",
        "\n",
        "Sipeed AIoT is an Edge AI MCU which is capable to perform neural network computation at fast speed. In the demo app, Mobilenet V1 model is used and transfer learning is used to train the model to differential between 5 classes of flowers.\n",
        "\n",
        "This notebook is to combine the steps to create the trained model that can be uploaded to the device.\n",
        "\n",
        "Acknowledgement:  DmitryM8 and the steps are adapted from [Instructables](https://www.instructables.com/id/Transfer-Learning-With-Sipeed-MaiX-and-Arduino-IDE/) with some modifications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2hnpFs6P8mC"
      },
      "source": [
        "## Clone the required files from Github\n",
        "\n",
        "DmitryM8 version of Mobilenet is used."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additional environtment setup @sistematika\n"
      ],
      "metadata": {
        "id": "TVxre9J33nKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation_models\n",
        "import segmentation_models as sm\n",
        "sm.set_framework('tf.keras')\n",
        "sm.framework()"
      ],
      "metadata": {
        "id": "YiCe385c3qxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "ZjIhBOJU3xuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZaQb4KqNBzW"
      },
      "source": [
        "# Clone the libraries to setup the libraries\n",
        "\n",
        "!git clone https://github.com/AIWintermuteAI/transfer_learning_sipeed.git\n",
        "!git clone https://github.com/sipeed/Maix_Toolbox.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyc9CowltO9q"
      },
      "source": [
        "### Install the tflite to kmodel conversion software\n",
        "Note that there is a bug in the get_nncase.sh in the Maix_Toolbox which is unable to extract the file. The steps below is the same as the script but the typo error is fixed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nowUGs2NB7Qn"
      },
      "source": [
        "%%bash\n",
        "cd Maix_Toolbox \n",
        "mkdir -p ncc\n",
        "mkdir -p workspace\n",
        "mkdir -p images\n",
        "mkdir -p log\n",
        "cd ncc\n",
        "wget https://github.com/kendryte/nncase/releases/download/v0.1.0-rc5/ncc-linux-x86_64.tar.xz\n",
        "tar -Jxf ncc-linux-x86_64.tar.xz\n",
        "rm ncc-linux-x86_64.tar.xz\n",
        "echo \"download nncase ok!\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aInHubWZQgzJ"
      },
      "source": [
        "## Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Wvu_zg6NstZ"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.applications import imagenet_utils\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Dropout,Flatten\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/transfer_learning_sipeed')\n",
        "from mobilenet_sipeed.mobilenet import MobileNet\n",
        "\n",
        "from keras.applications.mobilenet import preprocess_input\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLKCaC1cQ8nZ"
      },
      "source": [
        "### Download the flowers sample dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-6gYty7R3u8"
      },
      "source": [
        "# Download the flower photos\n",
        "\n",
        "%cd /content\n",
        "!curl -LO http://download.tensorflow.org/example_images/flower_photos.tgz\n",
        "!tar xzf flower_photos.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bumxZ1EFRpd_"
      },
      "source": [
        "### Define the parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN8wA-GN3AJK"
      },
      "source": [
        "# the parameters\n",
        "IMAGE_SIZE = 224\n",
        "ALPHA=0.75\n",
        "EPOCHS=20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsWFPaOcOyS-"
      },
      "source": [
        "def prepare_image(file):\n",
        "    img_path = ''\n",
        "    img = image.load_img(img_path + file, target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
        "    return keras.applications.mobilenet.preprocess_input(img_array_expanded_dims)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO_tDctxll5i"
      },
      "source": [
        "# function to define dropout, hidden layers and the number of output\n",
        "def build_finetune_model(base_model, dropout, fc_layers, num_classes):\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    \n",
        "    for fc in fc_layers:\n",
        "        # New FC layer, random init\n",
        "        x = Dense(fc, activation='relu')(x) \n",
        "        x = Dropout(dropout)(x)\n",
        "\n",
        "    # New softmax layer\n",
        "    predictions = Dense(num_classes, activation='softmax')(x) \n",
        "    \n",
        "    finetune_model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    return finetune_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a6QkUw2RnsH"
      },
      "source": [
        "### Transfer Learning using Mobilenet V1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5oc2DTvO4wf"
      },
      "source": [
        "# Using MobileNetv1\n",
        "base_model=MobileNet(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), alpha = ALPHA, \n",
        "                     depth_multiplier = 1, dropout = 0.001, include_top = False, \n",
        "                     weights = \"imagenet\", classes = 1000, backend=keras.backend, \n",
        "                     layers=keras.layers,models=keras.models,utils=tf.keras.utils)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqKI0E7oRH3h"
      },
      "source": [
        "### Define the last few layers\n",
        "I used 2 hidden layers and 100 and 50 nodes. More layers or nodes can be added but this will increase the model size and may not fit into Maixpy memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzXf_FlDl20y"
      },
      "source": [
        "FC_LAYERS = [100, 50]\n",
        "dropout = 0.5\n",
        "\n",
        "finetune_model = build_finetune_model(base_model, \n",
        "                                      dropout=dropout, \n",
        "                                      fc_layers=FC_LAYERS, \n",
        "                                      num_classes=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "big9oKAWqQ0N"
      },
      "source": [
        "for i,layer in enumerate(finetune_model.layers):\n",
        "    print(i,layer.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BayNJNWYSbr0"
      },
      "source": [
        "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies\n",
        "\n",
        "train_generator=train_datagen.flow_from_directory('/content/flower_photos',\n",
        "                                                 target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size=32,\n",
        "                                                 class_mode='categorical', shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgWO8TPyR7kY"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dErWjt8Bn6IV"
      },
      "source": [
        "finetune_model.summary()\n",
        "finetune_model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "step_size_train=train_generator.n//train_generator.batch_size\n",
        "history = finetune_model.fit_generator(generator=train_generator,steps_per_epoch=step_size_train,epochs=EPOCHS, shuffle=True)\n",
        "\n",
        "finetune_model.save('/content/my_model.h5')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YBIRTO4u9iM"
      },
      "source": [
        "# do a random test to confirm the model is working\n",
        "preprocessed_image = prepare_image('/content/flower_photos/roses/14494590921_3bb1dc7b88_n.jpg')\n",
        "predictions_flower = finetune_model.predict(preprocessed_image) \n",
        "print(predictions_flower[0][0]*100)    \n",
        "print(predictions_flower[0][1]*100) \n",
        "print(predictions_flower[0][2]*100) \n",
        "print(predictions_flower[0][3]*100) \n",
        "print(predictions_flower[0][4]*100) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-4DpV3i_kff"
      },
      "source": [
        "##Convert the Model\n",
        "h5 --> tflite --> kmodel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qALZ3-QSWs4"
      },
      "source": [
        "###h5 --> tflite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xh5cMw23YdaE"
      },
      "source": [
        "#convert keras to tflite format\n",
        "!tflite_convert  --output_file=/content/model.tflite --keras_model_file=/content/my_model.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHpfWFHgSccx"
      },
      "source": [
        "### tflite --> kmodel\n",
        "\n",
        "Prepare some test data for ncc util"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOO0M8wkORGi"
      },
      "source": [
        "%%bash\n",
        "cd /content\n",
        "\n",
        "mkdir /content/test_photos/\n",
        "mkdir /content/test_photos/daisy\n",
        "mkdir /content/test_photos/dandelion\n",
        "mkdir /content/test_photos/roses\n",
        "mkdir /content/test_photos/sunflowers\n",
        "mkdir /content/test_photos/tulips\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlXzn2bBO2vF"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "def recursive_copy(src, dest):\n",
        "    \"\"\"\n",
        "    Copy each file from src dir to dest dir, including sub-directories.\n",
        "    \"\"\"\n",
        "    \n",
        "    #copy only 10 files\n",
        "    count=0\n",
        "    for item in os.listdir(src):\n",
        "        file_path = os.path.join(src, item)\n",
        "\n",
        "        # if item is a file, copy it\n",
        "        if os.path.isfile(file_path):\n",
        "            shutil.copy(file_path, dest)\n",
        "\n",
        "        # else if item is a folder, recurse \n",
        "        elif os.path.isdir(file_path):\n",
        "            new_dest = os.path.join(dest, item)\n",
        "            os.mkdir(new_dest)\n",
        "            recursive_copy(file_path, new_dest)\n",
        "        if count == 10:\n",
        "          break\n",
        "        count+=1\n",
        "\n",
        "recursive_copy(\"/content/flower_photos/daisy\", \"/content/test_photos/daisy\")\n",
        "recursive_copy(\"/content/flower_photos/dandelion\", \"/content/test_photos/dandelion\")\n",
        "recursive_copy(\"/content/flower_photos/roses\", \"/content/test_photos/roses\")\n",
        "recursive_copy(\"/content/flower_photos/sunflowers\", \"/content/test_photos/sunflowers\")\n",
        "recursive_copy(\"/content/flower_photos/tulips\", \"/content/test_photos/tulips\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bby8_XS8KRBB"
      },
      "source": [
        "#convert tflite to kmodel format\n",
        "# this will take some time...\n",
        "%cd /content/Maix_Toolbox\n",
        "!./ncc/ncc -i tflite -o k210model --dataset /content/test_photos /content/model.tflite /content/model.kmodel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ5_9MQQxM_b"
      },
      "source": [
        "### Download the generated file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmYlPtM7xJTV"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/content/model.kmodel')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7az3bQj60Vk"
      },
      "source": [
        "After this step,\n",
        "\n",
        "download the kmodel to the  \n",
        "\n",
        "1.   Download the kmodel file in /content/model.kmodel\n",
        "2.   Create a label file. For the flower dataset the content of the label file is\n",
        "\n",
        "daisy\n",
        "\n",
        "dandelion\n",
        "\n",
        "roses\n",
        "\n",
        "sunflowers\n",
        "\n",
        "tulips\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cfwaYJ4-N8h"
      },
      "source": [
        "This is the micropython code to be executed on the Sipeed devices. \n",
        "(Do not run this in Colab)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8L4q7bpnYkj"
      },
      "source": [
        "import sensor, image, lcd, time\n",
        "import KPU as kpu\n",
        "lcd.init()\n",
        "sensor.reset()\n",
        "sensor.set_pixformat(sensor.RGB565)\n",
        "sensor.set_framesize(sensor.QVGA)\n",
        "sensor.set_windowing((224, 224))\n",
        "sensor.set_vflip(0)\n",
        "sensor.set_hmirror(0)\n",
        "sensor.run(1)\n",
        "lcd.clear()\n",
        "lcd.draw_string(100,96,\"MobileNet Demo\")\n",
        "lcd.draw_string(100,112,\"Loading labels...\")\n",
        "f=open('flowerlabel.txt','r')\n",
        "labels=f.readlines()\n",
        "f.close()\n",
        "task = kpu.load(\"/sd/model.kmodel\") \n",
        "clock = time.clock()\n",
        "while(True):\n",
        "    img = sensor.snapshot()\n",
        "    clock.tick()\n",
        "    fmap = kpu.forward(task, img)\n",
        "    fps=clock.fps()\n",
        "    plist=fmap[:]\n",
        "    pmax=max(plist)\t\n",
        "    max_index=plist.index(pmax)\t\n",
        "    a = lcd.display(img, oft=(50,0))\n",
        "    lcd.draw_string(0, 224, \"%.2f:%s                            \"%(pmax, labels[max_index].strip()))\n",
        "    print(pmax)\n",
        "a = kpu.deinit(task)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnC5EmFcnpum"
      },
      "source": [
        "This is the [Youtube Video](https://www.youtube.com/watch?v=0Pc0LwmRWRk) for the realtime inferencing using Sipeed Maixpy Go"
      ]
    }
  ]
}